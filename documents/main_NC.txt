
Adult-infant neural coupling mediates infants’ selection of socially-relevant stimuli for learning across cultures

Zhang, Wei 1, 2, Clackson, Kaili 1, Georgieva, Stanimira 1, Santamaria, Lorena 1, Reindl, Vanessa 3, 4, Noreika, Valdas 5, Darby, Nicholas 6, Valsdottir, Vaka 6, Santhanakrishnan, Priyadharshini 1, & Leong, Victoria 1, *

1 Early Mental Potential and Wellbeing Research (EMPOWER) Centre, Nanyang Technological University, Singapore
2 Cognitive Neuroimaging Centre, Nanyang Technological University, Singapore
3 Division of Psychology, Nanyang Technological University, Singapore
4 Section Child Neuropsychology, Department of Child and Adolescent Psychiatry, Psychosomatics and Psychotherapy, Uniklinik RWTH Aachen, Germany
5 Department of Psychology, School of Biological and Chemical Sciences, Queen Mary University of London, London, UK
6 Department of Psychology, University of Cambridge, UK


*Corresponding Author:
Victoria Leong
Early Mental Potential and Wellbeing Research (EMPOWER) Centre, 
Nanyang Technological University, Singapore 
Email: victorialeong@ntu.edu.sg

Abstract

Infants possess powerful learning abilities, but their neural resources must be deployed parsimoniously toward the most relevant information in a given social context. Adults curate infants’ information selection through ostensive marking of valuable content using social cues such as eye-contact. However, the neural mechanisms that support “social gating” of early learning remain unclear. Here, we demonstrate that – across Western and Asian cultures – adult-infant interpersonal neural coupling mediates infants’ selection of socially-relevant information for learning. Specifically, interpersonal neural coupling is regulated by the adult speaker’s level of eye contact and predicts selective learning of an artificial language that is paired with full (compared to partial or no) eye contact. Adult-infant neural coupling is a better predictor of selective learning than infants’ own neural activity, suggesting that this signal effectively captures important social influences on early cognition, and may provide insights into social valuation decision-processes that dictate early social learning.

(148 words)





1 Introduction
In a busy world, infants are surrounded by myriad stimuli that compete for attention. Amidst different actors, sights and sounds, infants must parsimoniously attend to and select information that is relevant for learning and action. Social ostensive cues - such as gaze, infant-directed speech, facial expressions, and contingent reactivity – indicate the social partner’s communicative intent and enhance infants’ receptivity to learning and communication (1). These multimodal cues are integrated probabilistically, with infants weighing their reliability and relevance to infer the speaker's intent and the significance of the conveyed information (2). This integration is supported by emerging evidence that ostensive cues dynamically reinforce one another; for example, vocal prosody increases the likelihood of gaze following (3), and the combination of direct gaze and infant directed speech synergistically enhances neural and behavioural responses in infants, supporting their ability to process and learn from social cues (4). The stages of social perception (detecting the social context and integrating cues), social valuation (inferring intent and assigning subjective value, based on factors like relevance and reliability) and social action (learning and responding) are fundamental processes in social decision-making that are conserved across species (5). In adult models, well-described neural circuits are known to subserve these stages (6, 5, 7): social perception is supported by activity in the medial temporal lobes and fusiform gyrus whilst inferring intentions is known to engage the posterior superior temporal sulcus, temporoparietal junction, anterior cingulate cortex (ACC) and medial prefrontal cortex (mPFC). Subjective value calculations are encoded in the mPFC, orbitofrontal cortex amygdala and ventral striatum, and social learning implicates the dopaminergic midbrain, striatum (including the nucleus accumbens, NAc), ACC and dorsolateral PFC. An exceptional example of social decision-making is the process of pair bond formation, which involves a seismic change in the perception and valuation of another individual. In prairie voles, a monogamous species of rodents, a crucial step in pair-bond formation is thought to involve PFC coordination of inter-regional neuronal oscillatory coupling with the NAc and amygdala to direct the flow of social information, linking neural representations of the social partner with reward (8, 9). However, little is known about social decision-making processes in early human development. Although human infants can perform social perception and valuation using ostensive signals as key inputs, the neural processes that underpin early social valuation and choice-making are largely unknown.
Direct gaze is thought to be one of the most salient ostensive signals for conveying communicative intent (1) and enhancing learning (see review (10)), and also elicits communicative behaviour from infants (11, 12). From birth, infants prefer to look at pictures of faces with direct gaze over averted gaze (13), and by 4 months, heightened brain responses to direct gaze suggest that direct gaze modulates neural circuits involved in social learning and communication (14, 15). Direct gaze is undoubtedly a highly salient social cue, but debate exists about whether ostensive signals merely modulate social attention, or whether they truly play a privileged role in referential learning. For example, Szufrnarowska and colleagues demonstrated that infants showed gaze-following to both an ostensive cue (direct gaze) as well as a salient non-ostensive cue (shivering) (16), although learning was not assessed. A replication study (17) confirmed that gaze-following effects were not unique to ostensive signals. Infants showed gaze-following responses to infant-directed speech (IDS), shivering and a non-verbal beep. However, only IDS cues subsequently elicited referential learning. For both shivering and beeps, infants’ gaze following behaviour was not associated with significant learning. A similar dissociation between attention and learning has been observed in more naturalistic learning contexts. A previous study (18) found that 9-month-old American infants learned Mandarin phonetic properties from a live teacher but showed no learning when the same teaching was presented via video, despite infants paying equal visual attention in live and video contexts. These results have led the authors to propose the "social gating hypothesis" which suggests that contingent social interaction is key to language learning in real-world settings, with the social brain acting as a “gate” on the computational mechanisms involved in language learning (19). Collectively, these data point to a larger role for ostensive cues in early decision-making – beyond social perception (i.e. modulating attention) they may in fact weight social valuation computations and thereby influence learning and action. 
Social brain imaging may shed light on the neural processes that underpin these decision stages. Interpersonal neural coupling, wherein neural activity between infants and caregivers becomes aligned during interactions has been proposed as a mechanism supporting social learning (20, 21). When comparing communication in a live context and via an online video platform, adult-infant cross-brain coupling has been shown to be stronger in the live context, and also to have stronger relationships with video coded measures of child empathic social engagement, including measures of the child’s gaze, involvement, empathy and cooperation (22). Interpersonal neural coupling has also been shown to be sensitive to ostensive gaze cues, as direct gaze leads to stronger bidirectional adult-infant neural influence (compared to averted gaze) (12), and interpersonal coupling is more strongly influenced by mutual gaze than by joint attention to an object (23). Indeed, the mPFC (a key region for inferring intention and value calculation) is activated in infants by direct gaze and by IDS (24, 25) and PFC activity has been shown to be synchronised between a mother and child during verbal conversations (26). Accordingly, it is plausible that the observed interpersonal neural coupling in regions such as the PFC could indicate estimation of the partner’s intent and reliability, informing value calculations for selective learning and decision-making in social contexts.
Here, we use concurrent measurement of interpersonal (adult-to-infant) and intrapersonal (within-infant) neural activity during a statistical learning paradigm to identify how speaker gaze, an ostensive signal, modulates infants’ selection of language stimuli for learning from a social partner in a pre-recorded video. We also measure attention and neural entrainment to speech as potential contributors to the process. Entrainment, the temporal alignment of neural oscillations to rhythmic stimuli such as speech or gestures, has also been proposed as a key contributor to interpersonal neural coupling (27). Some researchers argue that entrainment facilitates information exchange by enhancing attention and prediction (28), while others suggest that interpersonal neural coupling is simply an epiphenomenon of individual entrainment to common sensory inputs (29, 30). Accordingly, here we ask whether interpersonal neural coupling explains infant behaviour over and above effects of neural entrainment to the speech stimulus, thereby distinguishing the contributions of these processes. In highly controlled experimental settings using artificial languages delivered without ostensive signals, infants of 8 months have shown remarkable abilities to learn transitional probabilities, and to use these statistical regularities to segment words from continuous speech (31). Electroencephalography (EEG) studies further confirm that even newborns are able to track transitional probabilities in a similar way (32). Therefore, we expected that the presentation of a social ostensive cue (gaze) - even in a non-contingent video context – would be effective in modulating infants’ learning. Further, although eye-contact is considered a key communicative cue, evidence regarding cultural differences in mutual gaze during face-to-face interactions is mixed. While some researchers have found evidence that cultures differ in their interpretation of direct gaze (33) and in looking patterns to faces during interactions (34, 35), other results challenge the idea of cultural differences between Asians and Westerners leading to differences in levels of mutual gaze (36). To address the cross-cultural generalisability of effects of ostensive gaze, we conducted identical measurements with infants growing up in two different cultural contexts, a Western country (UK) and an Asian country (Singapore). 
Forty-seven infants aged 9.4 months on average from Singapore and the UK took part in the study, matched on age and sex (see Methods 4.1). During the experiment (see Fig. 1a), infants were presented with pre-recorded videos of a female adult speaking artificial languages (modelled on a standard paradigm (31)) under three conditions where the speaker’s gaze was parametrically manipulated: Full gaze (wearing clear glasses, eyes visible), Partial gaze (wearing dark glasses) and No gaze (wearing fully opaque glasses). The adult speaker’s EEG was pre-recorded during recording of the stimulus videos. For each gaze condition, infants first watched the videos while their EEG and attention to the screen were recorded during this Familiarisation phase. In the subsequent Test phase infants’ learning was assessed for each condition as the looking time difference between nonwords and words, given their expected novelty preference (longer looking time) for less familiar nonwords (31, 37).We predicted that infants would show selective learning for languages accompanied by Full gaze and no learning when speaker gaze was occluded. However, it was of interest to assess whether infants would show any learning during Partial gaze occlusion. Second, based on previous literature, we predicted that the gaze ostensive effect on learning would be mediated by inter-brain connectivity, over and above effects of neural entrainment to the speech signal. Finally, whilst we expected to uncover cultural differences in ostensive gaze processing between UK and SG cohorts, it was also of interest to assess which effects were conserved across cultures. 


2 Results

2.1 Speaker gaze, not attention, modulates selection of a socially relevant language stimulus for learning

Consistent with the theoretical framework of natural pedagogy (1), fully visible speaker gaze acted as an ostensive signal for selection of the most relevant stimulus for learning. As shown in Fig. 1d, across all infants, learning was significant for the artificial language which was paired with Full speaker gaze (t98 = 2.66, corrected p < .05), whereas no significant learning was detected for languages that were paired with Partial (t98 = 1.53, corrected p = .19) or no speaker gaze (t99 = 0.81, corrected p = .42), see also Table 1. Supplementary Materials Section 1 illustrates that individual infants with the highest overall learning also showed strongest learning in the Full gaze condition, but little or no learning with Partial or No speaker gaze.

Table 1. Performance metrics for the three gaze conditions (mean value ± standard error of the mean). Learning was measured as the looking time difference between nonwords and words, in seconds. A total of 47 infant participants contributed data.
Full gazePartial gazeNo gazeLearning / sec1.22 ± 0.460.76 ± 0.510.34 ± 0.42Total visual attention / sec22.91 ± 1.5021.48 ± 1.3623.34 ± 1.39Infants’ learning was independent of their total visual attention (Fig. 2a), which did not differ across gaze conditions (Full vs. Partial gaze t288 = 0.98, p = .33; Full vs. No gaze t288 = -0.27, p = .79, Partial vs. No gaze t288 = -1.25, p = .21, see Fig. 2b and Table 1) and did not correlate with learning t281 = -1.37, p = .17 across all gaze conditions, see Fig. 2c. Statistical analyses of two other visual attention measures showed similar patterns (see Supplementary Materials Section 2). Notably, total attention duration did differ between cohorts, with SG infants attending to stimuli significantly longer overall compared to the UK infants (t290 = 5.83, p < .0001, see Fig. 2d). Despite this, there was no difference in learning overall between the SG and UK cohorts (t294 = 0.85, p = .39). We also assessed infant’s language development using the Mac-Arthur Bates Communicative Development Inventory (CDI), focusing on gesture scores as the primary measure of expressive language at this age. There was no significant difference between scores of the SG and UK cohorts (t39 = 0.45, p = .65) and infants’ CDI scores were not significantly associated with learning (t273 = 0.36, p = .72).

In summary, here three viable and distinct language sets were offered by the same speaker, yet infants only learned one of the three proffered languages – marked by full gaze availability. This effect of ostensive gaze was observed across both country cohorts. We also observed a dissociation between infants’ learning and visual attention, as visual attention measures did not differ across gaze conditions, although learning did. Conversely, visual attention differed between SG and UK cohorts, whilst learning did not. Accordingly, gaze effects on infant learning cannot be attributed to simple modulation of attention.

2.2 Adult-infant cross-brain connectivity predicts selective learning whereas within-infant connectivity associates with expressive language

To assess neural substrates of infant learning, we performed partial least squares (PLS) regression analysis on the adult and infant neural connectivity measures in the 6-9 Hz infant alpha band (see Supplementary Materials Section 3 for identical analysis in the delta and theta bands). A PLS approach was chosen to effectively capture and contrast the summative contribution of entire interpersonal and intrapersonal neural networks toward infant learning and language outcomes. Neural connectivity was initially computed as a fully-connected directed adult-infant network using generalised partial directed coherence (GPDC, see Methods section 4.3.2) and then partitioned into the adult-to-adult (AA), infant-to-infant (II), adult-to-infant (AI), and infant-to-adult (IA) sub-matrices (Fig. 3a).
To identify significant connections, GPDC values were compared to a surrogate distribution. After correcting for multiple comparisons, no infant-to-adult (IA) connections exceeded the 95% confidence interval (CI) upper bound of the surrogate distribution, which aligned with our expectations given that adult EEG was pre-recorded. In contrast, significant connections were detected in all three of the other sub-matrices across all gaze conditions (Fig. 3b). Only connections that were significantly above chance in at least one of the three gaze conditions were entered into the subsequent PLS analyses.
As shown in Fig. 4a, the PLS analyses revealed that only adult-infant (AI) GPDC connectivity significantly predicted infant learning above chance (compared to surrogate data), with the first AI GPDC component explaining 24.6% of variance in infant learning. By contrast, within-infant (II) GPDC connectivity did not significantly predict infant learning. However, II GPDC components did significantly predict infants’ CDI gesture scores (see Fig. 4b), with the first II component explaining 33.7% of variance in CDI gesture scores. The relevant component loadings and scalp topographies are shown in Fig. 4c and Fig. 4d. For the first AI GPDC component, peak loading was observed on certain key connections, including adult Fz to infant Fz. Supplementary Materials Section 4 presents additional analyses performed at the single connection level, showing that this connection is significantly modulated by speaker gaze, (Full gaze > Partial or No gaze, t221 = 3.48 and BHFDR-corrected p < .05), consistent with previous published research (12).
To confirm the observed double dissociation between AI and II on learning and CDI gesture scores respectively, we performed a 10-fold cross-validation estimated through 1000 nonparametric bootstrap resampling iterations (Fig. 4e and 4f). This cross-validation confirmed that for PLS prediction of learning, AI GPDC performance was significantly higher than that of II GPDC (t1998 = 27.7, p < .0001), whereas for PLS prediction of CDI gesture scores, II GPDC performance was significantly higher than that of AI GPDC (t1998 = 44.7, p < .0001).
2.3 Neural entrainment to the speech amplitude envelope is modulated by speaker gaze but does not predict learning

In previous studies, neural entrainment to the speech amplitude envelope has been proposed as a mechanism of interest for phonological processing (38, 39) as well as a potential contributor to cross-brain connectivity (40, 41).Accordingly, here we examined whether speaker gaze modulated infants’ neural-speech entrainment (NSE) during the Familiarisation phase, measured by the peak cross-correlation between infants’ EEG signals and the amplitude envelope of the speaker’s audio waveform (illustrated in Fig. 5a). Compared to a surrogate distribution (95% CI upper bound), significant NSE was observed only in the Full gaze condition. Entrainment was detected across three frequency bands—delta, theta, and alpha—and nine EEG channels (Fig. 5b), after correcting for multiple comparisons. Specifically, significant NSE was identified in the delta band at C3, theta band at F4 and Pz, and alpha band at C3 and Cz (all at corrected p < .05). A visualisation of this analysis (delta band at C3) is provided in Fig. 5c, illustrating the real data against the surrogate distribution for each gaze condition. We further assessed whether NSE was a predictor of infant learning using the PLS procedure conducted previously for cross-brain (AI) and within-infant (II) connectivity. This PLS analysis revealed that NSE did not significantly explain infant learning (see Supplementary Materials Section 5), even though NSE levels were sensitive to speaker gaze.
2.4 Interbrain connectivity mediates gaze-selective learning independent of entrainment
Recall that thus far, an ostensive effect of gaze on learning has been observed and a PLS component of interbrain connectivity (AI GPDC) has been identified to predict learning. Separately, NSE sensitivity to gaze was detected, with significant entrainment observed only in the Full gaze condition. Here, we bring these identified neural components together in a mediation analysis to assess whether each mediates the effect of gaze on infant learning. Specifically, infant learning was entered as the dependent variable with gaze condition as the independent variable. NSE and AI GPDC (PLS) measures were assessed as potential mediators separately. Further details of this analysis are given in methods Section 4.5. The significance of each pathway was evaluated using linear mixed effects (LME) modelling. No significant effects of country were detected on the key measures of interest in this analysis (see Supplementary Materials Section 6).
Adult-infant interpersonal connectivity significantly mediated the relationship between speaker gaze and learning (indirect effect: ? = 0.52 ± 0.23, p < .01; Fig. 6). Specifically, Full gaze was associated with higher levels of AI connectivity (Full vs. Partial gaze ? = 0.37, t111 = 0.85, p = .40; Full vs. No gaze ? = 1.01, t111 = 2.53, p < .05; Fig. 6a), and higher AI connectivity was associated with increased learning by infants (? = 0.50, t224 = 8.58, p < .0001; r = 0.49, p < .0001 in Fig. 6b). By contrast, there was no direct effect of speaker gaze on learning (? = 0.06 ± 0.12, p = .65). 
For NSE, all five features previously identified (Section 2.3) as being significant in Full gaze were independently tested as potential mediators of the gaze effect on learning (see Supplementary Materials Section 7). In Fig. 6 we present results for delta C3 NSE since this was the only feature for which NSE was significantly higher in Full as compared to Partial or No gaze (? = 0.40, t112 = 2.28, p < .05; Fig. 6c). However, this NSE feature did not predict or correlate with learning (? = -0.12, t112 = -1.22, p = .23; r = -0.11, p = .24 in Fig. 6d). Further, none of the NSE features acted either directly or indirectly to mediate the effect of gaze on learning (e.g., ? = -0.05 ± 0.04, p = .16; ? = 0.35 ± 0.20, p = .08 for delta C3). Interestingly, the interaction analysis revealed that gaze had a modulatory effect on the relationship between NSE and interpersonal connectivity (Fig. 6e). Specifically, increased delta C3 NSE was associated with stronger AI connectivity, but only in the No gaze condition (? = 0.34, t111 = 2.02, p < .05). Accordingly, although NSE features were sensitive to gaze, none of them mediated the effect of Full gaze on infant learning.
Finally, within-infant connectivity (II GPDC) did not show significant mediation effects of gaze on learning (? = 0.06 ± 0.25, p = .82), as described in further detail in Supplementary Materials Section 7.



3 Discussion
For infants, learning typically occurs in social contexts and adult partners play a crucial role in providing ostensive cues for infants’ decision processes of social perception, valuation (of relevance and reliability) and selection for learning. A-priori we predicted that infants would show selective learning for languages accompanied by Full gaze and no learning when speaker gaze was occluded. This prediction was supported, and we also noted no significant learning in the Partial gaze condition. Second, we predicted that gaze ostensive effects on learning would be mediated by inter-brain connectivity, over and above effects of neural entrainment to the speech signal. This prediction was again supported. Specifically, mediation analysis demonstrated that only adult-infant (AI) neural connectivity significantly mediated the relationship between speaker gaze and learning, with Full gaze associated with higher levels of AI connectivity, and higher AI connectivity associated with increased learning by infants. This finding replicates and extends earlier work demonstrating that the availability of speaker gaze is associated with increased interpersonal neural connectivity in the context of infant-adult communication (12). 
Entrainment and learning. Crucially, gaze ostensive effects on learning could not be explained by neural speech entrainment (NSE), which reflects phonological encoding of temporal properties of the speech signal and its neural representation in auditory regions (38), although NSE itself was modulated by gaze. Significant NSE was only observed in the Full gaze condition (specifically, at C3 in the delta band, at F4 and Pz in the theta band, and at C3 and Cz in the alpha band). However, NSE did not directly predict infant learning. Interestingly, NSE was positively correlated with AI connectivity in the No gaze condition, which may reflect a strategy to optimize sensory information that is available in the absence of ostensive cues, such as acoustic patterns. For example, phonological encoding or rhythmic prediction may be enhanced by NSE (42), but these outcomes were not measured in this study. Also similar to findings with early blind individuals (43) this strategy could suggest a compensatory mechanism where the synchronization of available sensory inputs along with brain functional connectivity is enhanced when visual information is limited.
Interpersonal and intrapersonal connectivity. When comparing interpersonal and intrapersonal connectivity, we noted that infants’ intrapersonal connectivity predicted their early communicative gestures scores but did not relate to stimulus selection for learning in this task. This may suggest that the calculated GPDC within-infant connectivity metrics are stronger indicators of the infant's overall social-cognitive developmental maturity than of transient social learning dynamics. This is consistent with findings that within-brain functional connectivity patterns in the left temporal lobe during infancy predict language skills in later childhood (44).
Attention and learning. Recall that infants selectively learned the artificial language which was delivered with Full speaker gaze, whereas no significant learning was detected for languages delivered with Partial or No speaker gaze. This ostensive effect of gaze was dissociated from infant visual attention in two ways. First, while learning differed across gaze conditions, measures of visual attention did not. Second, UK and Singapore cohorts exhibited differences in visual attention but not in learning performance. This suggests that whilst attention is required for learning, the two processes are differentially implicated in ostensive gaze, and only gaze-mediated learning is related to interpersonal neural coupling in this paradigm. This apparent mechanistic dissociation between attention and learning effects of ostensive cues is consistent with results from previous studies. Findings by Okumura et al. (17) parallel those of the current study as an overt communicative cue (IDS in their study) enhanced learning by 9-month-old infants, but there were no differences in measures of infant visual attention between conditions with and without this ostensive cue. In addition, Kuhl and colleagues have shown that naturalistic language learning (measured by phonetic discrimination) occurs in live interaction settings, but not when similar stimuli are presented via pre-recorded video, despite infants paying equal attention to video and live presentations (18). Taken together, these results support the view that ostensive cues play a distinct role in infant learning, above and beyond attentional salience and orienting effects. Here, we identify interpersonal neural coupling as a potential marker of this ostensive learning effect. 
Cross-cultural effects. Finally, it was of interest to examine cross-cultural similarities and differences in ostensive gaze processing between UK and SG cohorts. We found that infants from both countries responded similarly to the gaze manipulation in their measured learning behaviour and neural connectivity metrics. This suggests that sensitivity to gaze cues is not specific to western cultures, although responses may differ in cultures where parent-child interactions are characterised by physical proximity and touch rather than direct gaze, such as some Arab cultures (45). However, we did observe a cultural difference with Singaporean infants looking significantly longer at the adult on the screen than their UK counterparts during the familiarization phase. We propose that this is due to an outgroup effect as the adult speaker was native English, which may have attracted the attention of the Singaporean infants due to the novelty of less familiar western facial features. Nonetheless, this novelty effect did not increase learning or modulate the measured neural connectivity metrics.
Limitations. One limitation of the current study is its relatively small sample size (N=47) and a related constraint in detecting small effect sizes. For example, we were able to detect the main effect of learning in the Full gaze condition which was of a small-to-moderate effect size (Cohen's d = 0.27, observed power = 0.75), but could have missed a smaller effect in the Partial gaze condition. Further, as the aim of the study was to carefully isolate changes in gaze availability and measure learning, it was necessary to design a highly controlled task that constrained naturalistic interaction and responsivity by the adult speaker. Accordingly, further studies are needed to assess the generalizability of these effects in more naturalistic and interactive settings.
In conclusion, the current study provides evidence that interpersonal neural coupling may explain the effect of ostensive gaze in stimulus selection for learning in social contexts. Further, interpersonal neural coupling is a better predictor of selective learning than infants’ own neural entrainment activity and attention. This suggests that the interpersonal signal effectively captures social influences on early cognition, and may provide insights into social valuation decision-processes that are involved in early social learning.



4 Methods
4.1 Participants
The inclusion criteria were as follows: 1. Infants aged between 8 and 10.5 months. 2. Infants with no diagnosed developmental or neurological problems as assessed by maternal report. 3. Infants raised in English-speaking households, as oscillatory brain activity is thought to be influenced by native language properties (46). 4. Mothers screened to exclude mental health issues or learning difficulties that could affect their infants' development.
Infant participants were tested at two sites in different countries: the University of Cambridge in the United Kingdom (UK) and Nanyang Technological University, Singapore (SG). The same experimental protocol and EEG acquisition setup was implemented at both sites. UK infants were from English speaking households, and SG infants were from English-Chinese bilingual families.
Fifty-five infants were recruited, but eight did not contribute data, due to either infant fussiness or accidental software failure. The remaining 47 infants (29 from UK and 18 from SG) had a mean age of 286 days (9.4 months) with a female ratio of 40.4% (19/47) (SG mean age = 294 days, range 251 – 323, 7/18 female; UK mean age = 282, range 245 – 315, 12/29 female). No significant country differences were detected for age (t35 = -2.0, p = .05) or sex (?²1 = 0.03, p = .87), but age, sex, and country were entered as covariates in subsequent statistical analyses where applicable (see Section 4.3.5 for details). Note that analysis of behavioural results (learning) was based on data from all 47 participants who completed the experiment, however, analyses involving EEG were carried out on subset of 42 participants who had both usable EEG and behavioural data. The sample size was estimated to be sufficient based on effect sizes reported in similar studies on infant word learning (47). A-priori power calculation (for t-test analysis) indicated that N=45 participants would be required to achieve a statistical power of 0.8 at an alpha level of 0.05. A detailed summary of participant demographics, including infant age and sex, maternal age and education, and data exclusion criteria, is provided in Supplementary Materials Section 8.
Parents provided informed consent on behalf of their infants and were free to withdraw from the study at any point in accordance with the Declaration of Helsinki. The protocol was approved by the Cambridge Psychology Research Ethics Committee: reference PRE.2016.029, and by the Nanyang Technological University Institutional Review Board: reference IRB2019-06-030.
4.2 Study protocol
4.2.1 Experimental design and manipulation of speaker gaze
The study followed a repeated measures design whereby each infant watched videos of a female native British English speaker presenting three different artificial languages paired with three gaze conditions respectively (Fig. 1a): Full gaze, partially occluded gaze (Partial gaze), and fully occluded gaze (No gaze). The three gaze conditions were achieved by placing polarising filters on both the speaker's glasses and the camera, with the speaker wearing the same glasses throughout. By adjusting only the camera-side polarising filter’s angle, we controlled eye area visibility in the videos while maintaining consistent recording conditions for the adult speaker (i.e. the speaker’s view was not occluded). This ensured that any differences in infant behaviour and brain activity could be attributed solely to differences in infants’ perception of the speaker’s gaze availability, rather than differences in the speaker’s experience whilst recording the stimuli. Pairings of language and gaze condition, and the order of presentation of gaze conditions were counterbalanced across participants (Fig. 1c).
4.2.2 Design of artificial language stimuli 
Three different but phonologically equivalent artificial language sets were created so as to ensure that a language that had already been heard was not re-used on the same infant in a different gaze condition. Each language set consisted of 12 unique syllables, each formed by a consonant-vowel combination, and these syllables were organized into four trisyllabic words, following the artificial language structure commonly used in previous statistical learning research (31). For example, one set might include words like "pe-tu-do", "ki-bu-to", "di-lo-ga", and "ku-re-pa". The syllables for each language were distinct. Syllables were produced at a continuous rate of one syllable every 333 ms (3 Hz), with no intonation or prosody. Since the stimuli were produced by a human speaker, any naturally-occurring differences in intensity were removed by digital equalisation, with loudness equalised to a playback volume of 61 dB. We further selected recordings that were closely matched for pitch, to ensure no significant differences in mean pitch across gaze conditions 
Infants' learning of the artificial language was assessed using "words" versus "nonwords" from each language set. "Words" were valid words from the language, with 100% transitional probability between syllables (e.g., "di-lo-ga"; hyphens indicate within-word boundaries). The "nonwords" were made of three-syllable strings spanning a word boundary. As shown in Fig. 1b, these nonword syllable strings had a one-third likelihood of occurring together, as they only occurred when one particular word followed another (e.g., "ga ku-re" occurred when "di-lo-ga" was randomly followed by "ku-re-pa"). The syllable sets, video recordings, and stimulus quality control procedures are detailed in Supplementary Materials Section 9.
4.2.3 Task structure 
The experiment was designed with three identical repeated blocks. Each block consisted of three gaze conditions (Full gaze, Partial gaze, and No gaze), with each condition including a Familiarisation phase followed by a Testing phase. Blocks were constructed this way so that even an infant who only completed one block contributed data to all three gaze conditions, and to minimize unbalanced effects of fatigue or non-completion. Each block lasted approximately ten minutes.
4.2.3.1 Familiarisation phase
The Familiarisation phase exposed infants to the artificial language, allowing them to calculate transitional probabilities for defining word boundaries. In each gaze condition within a block, infants watched a 60-second video of the female adult speaker delivering the artificial language. During each 60s video, 180 syllables in total were presented at a rate of 3 syllables per second without inter-word pauses, with each of the four words occurring 15 times and each word-pair transition occurring five times. For example, the speech might sound like: "pe-tu-do ki-bu-to di-lo-ga ku-re-pa di-lo-ga pe-tu-do ……" (the hyphen indicates the three syllables within the same word, see Fig. 1b). The infants' gaze at the adult speaker videos was monitored, and visual attention to the screen was measured. Additionally, infant EEG was recorded throughout. Further details of the setup of the Familiarisation phase are provided in the Supplementary Materials Section 10.
4.2.3.2 Testing phase
To assess word learning, infants viewed the same speaker producing isolated words or nonwords. Learning was assessed by comparing the looking times towards the screen for words and nonwords per condition. The premise for using looking times is that, provided sufficient familiarisation with the language, the infant will show a novelty preference and look for longer at the less familiar nonwords (31, 37). Thus, it was expected that the words, whose syllables co-occurred more frequently (i.e. had higher transitional probabilities), would be more familiar and thus yield shorter looking times than nonwords.
During the Testing phase, videos of the adult speaker appeared pseudo-randomly on either side of the screen, with a single test item (a word or nonword from the language used in the preceding Familiarisation phase), was repeated 12 times, with 900 ms of silence accompanied by a black screen between each repetition. In total, two words and two nonwords were presented in a single Testing phase in pseudo-random order. Infant looking times were recorded based on their head-turning toward the side of the screen and analysed using both automatic video coding (in-house Matlab scripts) and manual checking. Further details of Testing phase implementation are provided in the Supplementary Materials Section 11.
4.2.4 Measures of language development
Mothers assessed their child’s receptive and spoken language via self-report using the MacArthur-Bates Communicative Development Inventories (CDI) (48). Here, we focused on scores for the use of nonverbal communicative actions and gestures (rather than words or phrases), as these were most representative of the language development stage for young infants participating in the study, who had limited verbal skills.
4.3 Data acquisition, preprocessing and analyses
4.3.1 EEG acquisition and preprocessing
EEG was recorded separately from infants (during testing) and from the female adult experimenter (during recording of the video stimulus prior to infant testing) using a BIOPAC Mobita mobile amplifier with a 32-channel Easycap (Brain Products) electrode system following the international 10-20 placement. Data were acquired using Acqknowledge 5.0 software, at a 500 Hz sampling rate. The ground electrode was affixed to the back of the neck as this location is the least invasive. Channels were online referenced to the average.
Since the adult data were pre-recorded, we only used recordings where all the EEG data were of a high quality and fully usable. For infant recordings, bad EEG channels were identified by visual inspection and removed from further analyses. No interpolation was performed and missing data was marked for exclusion in the subsequent GPDC connectivity analyses. Following this, both infant and adult EEG data were average re-referenced, downsampled to 200 Hz and bandpass filtered in the range of 0.1 Hz - 45 Hz. Filtering was applied using an inverse FFT filter via the eegfiltfft.m funtion in EEGLAB toolbox (49) with default settings. All preprocessing steps were conducted on the full Familiarisation data EEG registration.
Artifact rejection was performed on infant EEG data using both manual and automated steps, and adult EEG data corresponding to the same time periods were also excluded for each participant. For manual rejection, we video coded infants’ behaviour at the time precision of individual frames (25 fps, 40 ms per frame) to identify time periods during the experiment when the infant was moving or inattentive (not looking at the screen). These data were excluded entirely from the analysis. An average of 36.4% of the data were retained per infant after this first stage of manual rejection. Next, each attended data segment was subjected to an automatic artifact rejection algorithm. For this purpose, the attended segments were divided into 1-second (200 samples) epochs, and baseline correction (mean removal) and linear detrending were applied to each epoch. Epochs with minimum or maximum values outside the predetermined boundaries of -150 and +150 µV were automatically rejected. Finally, all retained epochs were visually inspected for additional artifacts that were not detected by the preceding steps. In totality, this resulted in an average of 32.9% of data per participant retained for analysis, see also Supplementary materials section 12, which provides details of data retained at each pre-processing stage.
4.3.2 Measuring neural connectivity using generalised partial directed coherence
Partial directed coherence (PDC) (50) is a validated method for assessing brain connectivity in adult-infant dyads (12). This technique provides a direct, directed measure of information flow between network nodes, estimated using a Granger Causal (51) framework. Generalised partial directed coherence (GPDC) quantifies the directed flow of information from channel j (the ‘Sender’) to channel i (the ‘Receiver’) relative to the total predictive contribution of j across all channels in the network. Here, we used GPDC (52) calculated using the eMVAR (Extended Multivariate Autoregressive Modelling) Toolbox (53) in Matlab. GPDC is an adapted version of PDC that uses weighted averaging across receivers, providing better variance stabilization and scale invariance (54). The detailed implementation of GPDC is provided in Supplementary Materials Section 13.
We chose to focus our GPDC analysis on 9 channels, comprising F3, Fz, F4, C3, Cz, C4, P3, Pz, and P4 (representing bilateral frontal, central, and parietal regions). This smaller subset of channels was used as the GPDC metric cannot be applied to data with missing nodes (e.g. rejected channels), and our previous analyses suggested that interpolation techniques are unsatisfactory as they may introduce bias. Accordingly, we chose a minimal 9-channel array, representing a balanced spatial topography, for which sufficient usable data (after pre-processing for artifacts) was available. This vertex-focused topography also shows lower contamination by speech artifacts (55), which were of potential concern since the adult was producing speech during the EEG recording.
GPDC estimates were obtained for each 1.5s EEG epoch with 50% overlap for each channel This balances temporal resolution with frequency stability, capturing around ten cycles of alpha oscillation per window. The windowing procedure and GPDC calculation was applied only on the continuous cleaned EEG data, with no concatenation of separate segments of clean data (i.e., any windows that contained previously identified artifacts or windows at the end of the recording that were less than 1.5s were excluded from analysis). Finally, the mean GPDC value for each participant pair was calculated by averaging across windows, separately for each gaze condition and block.
This study focused on GPDC within the infant alpha band, defined as the range from 6-9 Hz, as this range has been identified to be functionally equivalent in infants to the adult alpha rhythm (56). Focusing on a common 6-9 Hz band (used for both adult and infant) is informed by a convergence of previous adult-infant dyad EEG research, namely: 1. Current practice in adult-infant brain connectivity research supports the use infant alpha frequency range when calculating connectivity strength (see reviews (57, 58)). 2. In a previous study (12), adult-infant GPDC strength within the 6-9 Hz range was found to be influenced by adult speaker gaze. 3. Brain network topology in the alpha band is influenced by adult-infant interaction patterns (59). 4. The alpha band is less affected by facial myogenic and speech artifacts and exhibits high test-retest reliability in infants (60). For completeness, we also report the GPDC results in delta and theta band in the Supplementary Materials Section 3.
4.3.3 Measuring neural-speech entrainment (NSE) using cross-correlation
Cross-correlation analysis is often used to capture entrainment strength between EEG activity and auditory speech stimuli (61, 62), assessing temporal dependencies between EEG signals and speech envelopes.
The Hilbert transform was used to compute the speech amplitude envelope, downsampled to match the EEG sampling rate for alignment. EEG power in the delta (1-3 Hz), theta (3-6 Hz), and alpha (6-9 Hz) bands was likewise computed using the Hilbert transform. Cleaned data of EEG segments corresponding to the first six syllables of each phrase were selected to capture neural entrainment, separately for each gaze condition and block, as this early phase typically exhibits strong neural oscillatory entrainment to the speech envelope (63, 64).
To account for potential non-linear relationships, both EEG power and the speech envelope were rank-transformed for a Spearman correlation. Cross-correlation analysis (via Matlab’s xcov function with normalized coefficients) was applied to calculate the strength of entrainment. For each six-syllable window, we computed cross-correlations within a frequency-band-specific lag (lag range = ±sampling rate / upper bound of the band frequency, e.g. lag range for alpha band = ±200 / 9 ? ±22 time points). The absolute peak correlation value within this window was taken as the measure of entrainment strength.
4.3.4 Generation of surrogate data for significance testing
To assess whether the computed neural GPDC and NSE values were spurious, we performed significance testing against a surrogate dataset for both indices, corrected for multiple comparisons across different channels and frequency bands. The surrogate dataset was generated by randomly disrupting temporal dependencies between signals, providing a chance-level benchmark, a procedure commonly used in previous studies (65, 28, 61, 66).
GPDC. For each participant and each channel, the infant and adults’ EEG epochs were randomly shuffled in time, thus preserving spectral content but disrupting global temporal alignment. The same GPDC computation pipeline was then applied to the shuffled data. This process was repeated 1000 times per participant and then averaged to obtain a group level surrogate distribution of GPDC values. The 95% CI upper bound of this surrogate distribution was taken as the threshold value (equivalent to p < .05) for determining significance for each connection. Correction for multiple comparisons was performed using the Benjamini-Hochberg False Discovery Rate (BHFDR) procedure (67).
NSE. For each participant and channel, surrogates were created by replacing the original speech segments with random segments of equal length drawn from a different language set, and then re-combined with the infants’ EEG. The same NSE computation pipeline was then applied to this recombined data. A total of 1000 surrogate datasets were generated at the group level, and the resulting group mean values were used to establish a 95% confidence interval for each EEG channel and frequency band. The observed NSE data means were then compared to this confidence interval, with those exceeding the upper bound considered significant (equivalent to p < .05). Correction for multiple comparisons was performed using the BHFDR procedure.
4.3.5 Statistical analyses
Where applicable, age, sex, and country were entered as covariates in our statistical analyses. P-values from multiple comparisons were corrected using the Benjamini-Hochberg False Discovery Rate (BHFDR) procedure (67). For experimental measures with repeated measurements (EEG, learning, and visual attention measures assessed across 3 conditions and 3 blocks), linear mixed-effects (LME) models were used with age, gender, and country as covariates, and participant ID as a random effect to account for repeated measurements and inter-participant variability. In Sections 2.1 and 2.2, LME models were used to assess differences in learning and visual attention across gaze conditions and countries, and also the relationship between CDI scores and learning. In Section 2.4, LME models were used in the mediation analysis to assess: (1) gaze effects on AI connectivity and NSE; (2) relationships between AI connectivity/NSE and learning; and (3) NSE-gaze interaction effects on AI connectivity (see also Methods 4.5). Partial Pearson correlations complemented these analyses by quantifying neural-behavioral relationships. For individual demographic information measurements (such as CDI gesture scores and age), Welch t-tests were used for between-country comparisons. Paired t-tests were used to determine whether learning was significant (nonword looking time compared to word looking time) in each gaze condition , following previous studies (31).
4.4 Prediction analyses with partial least squares regression
In results Section 2.2 and 2.3, partial least squares (PLS) regression was used to determine whether specific neural connectivity (e.g., AI GPDC and II GPDC) or NSE features could predict learning outcomes or CDI gesture scores while controlling for covariates such as age, sex, and country. PLS was chosen because it combines principal component analysis (PCA)-like dimensionality reduction with linear regression, identifying components in the predictor variables (e.g., neural measures) that best maximize covariance with the response variables (e.g., learning performance), with each component represented by loadings that indicate the linear contribution of each original variable to the predictive pattern. This method is particularly suitable for handling features prone to high collinearity, such as GPDC from multiple EEG channels, while providing interpretable components that linearly correspond to behavioural outcomes (68). PLS components are ordered by the amount of variance they explain. For interpretability, reporting is focused on the first component as this captures the most covariance between predictors and outcomes. To evaluate the reliability and generalizability of the PLS models, we performed three validation analyses (based on prior literature (69, 70)): 
1. Goodness-of-fit evaluation: Predictive performance (R² between real and predicted learning outcome values) was compared between real and shuffled surrogate datasets for each modality to identify significant predictors. Real prediction performance (R²) was assessed against the 95th percentile of the surrogate distribution to determine significance (equivalent to p < .05).
2. Component loading estimation: Bootstrapping (1000 iterations) was applied to estimate the loadings of key components within the PLS model, providing robust feature evaluations suited to small sample sizes (71). Specifically, we used the 1000 surrogate datasets (GPDC or NSE) generated previously to perform identical surrogate PLS regression analyses.
3. Cross-validation: Bootstrapping was combined with 10-fold cross-validation on resampled data to ensure reliable and generalizable predictions, a procedure applicable for PLS-based models (72).
4.5 Mediation analyses
In results Section 2.4, mediation analysis (73) was applied to identify and quantify the relative strengths of direct and indirect pathways through which gaze status could influence learning outcomes. Specifically, we wished to test whether the effects of gaze on infant learning were indirectly mediated through neural features such as AI GPDC or NSE. Mediation analysis was implemented using linear mixed-effects (LME) models instead of general linear models, as LME models provide a suitable framework for analyzing pathways in mediated relationships while accounting for the correlation structure of repeated measurements (74). To quantify and evaluate the significance of each pathway within the mediation model, we performed two analysis steps: (1) LME modelling to estimate the standardised coefficient value and significance, and (2) nonparametric bootstrapping with 1000 resamples to estimate the effect size distributions and confidence intervals of the direct and indirect effects (75). The direct effect was calculated as the coefficient for gaze when both gaze and the mediator were included as predictors of learning (thus controlling for the mediation effect). The indirect effect was calculated as the product of: (a) the coefficient of gaze predicting the mediator and (b) the coefficient of the mediator predicting learning while controlling for gaze.
The adult-infant neural connectivity feature entered into the model corresponded to the loadings of the first component of AI GPDC, identified through the previous PLS analysis reported in Section 2.2. Similarly, we identified five possible NSE features (channel C3 for delta band, Pz and F4 for theta and C3 and Cz for alpha band) based on the PLS analysis in Section 2.3. These were tested in separate mediation models (shown in Supplementary Materials Section 7), and the delta C3 model was reported in the main manuscript as this was the only one with a significant moderation effect.
Finally, to assess whether within-infant (II) connectivity also mediated gaze effects on learning, we replaced AI GPDC with its II GPDC analogue (the loadings of the first PLS component) in a separate mediation model reported in Supplementary Materials Section 7.

Data Availability
The data that support the findings of this study are not openly available due to reasons of sensitivity but are available from the corresponding author upon reasonable request. Data are located in controlled access data storage at Nanyang Technological University. 

Code Availability
Major analysis scripts are available on GitHub (https://github.com/Baby-Linc-Singapore/BABBLE_CODE). 

Acknowledgement
This research is supported by the RIE2025 Human Potential Programme Prenatal/Early Childhood Grant (H22P0M0002), administered by A*STAR. VL is supported by the Ministry of Education, Singapore, under its Academic Research Fund Tier 2 (MOE-T2EP40121-0001) and by a Social Science & Humanities Research Fellowship (MOE2020-SSHR-008).
Special thanks to Eszter and Diarmid Campbell for invaluable practical advice on the use of polarising filters to modulate visibility of the speaker’s eyes while still allowing the speaker to read syllable strings from the autocue.
Thanks also to Melis Çetinçelik, Marina Wenzl, Winnie Wee, Ivfy Foong, Teo Kai Xin, Dorcas Keow, Yvonne Chia, Jamie Lee, Sim Jia Yi, Lois Timothy, Arya Bhomick, Nastassja Fischer, and Lee Kean Mun for assistance with data collection and analysis.
We thank and acknowledge the Cognitive Neuroimaging Centre, Nanyang Technological University, Singapore for computational resources used in data analysis.



FIGURES

Fig. 1. Overview of experimental design and learning results. (a) Summary of the experimental protocol: 1. Pre-recording: Videos were recorded of a British female adult speaking a continuous artificial language, with EEG recorded simultaneously. Three different but phonologically-matched language sets were recorded and paired with different gaze conditions. 2. Familiarisation phase (FP): Infants watched pre-recorded video in one gaze condition, displayed in the centre of the screen. Infant attention and EEG were recorded. 3. Testing phase (TP): Infants watched word / nonword fragments of videos from same gaze condition, pseudo-randomly displayed on the left or right of the screen. Looking time differences between nonwords and words (in seconds) were calculated as a measure of learning. Familiarisation and Testing phase were then repeated for different gaze conditions in a counterbalanced order. (b) Example of artificial language speech, words, and nonwords. Speech: Continuous sequence of syllables without pauses between syllables or words. Word: A set of three syllables with 100% transition probability, indicated in the same colour (e.g., "pe-tu-do"). Nonword: A set of three syllables spanning a word boundary, with 33.3% transition probability (e.g., "do ki-bu" which crosses two words). (c) Illustration of experimental temporal sequence within a block. A block includes three different gaze conditions, each with a Familiarisation phase (FP; 60-seconds of video) and a Testing phase (TP; 2 words and 2 nonwords, each repeated 12 times). The block sequence shown in (c) was repeated three times in the full experiment. The pairings between language-set and gaze condition and the presentation order of gaze conditions were counterbalanced across infants. (d) Learning performance was significant during the Full gaze condition, as indicated by paired t-tests comparing the looking time difference between nonwords (NW) and words (W) measured during the Testing phase. Error bars represent standard error of the mean (SEM). "ns" indicates not significant and "*" indicates p < .05.


Fig. 2. Relationship between infant visual attention and learning. (a) Three measures of infant visual attention were assessed during the familiarization phase: attention onsets (the number of times infants shifted their gaze to the screen), average attention duration (average length of each look), and total attention duration (sum of all looking times). Here, only the results for total attention duration are shown. Results for the other attention measures are provided in Supplementary Materials Section 2. (b) Comparison of total attention duration across Full, Partial, and No gaze conditions showed no significant difference (Full vs. Partial gaze t288 = 0.98, p = .33; Full vs. No gaze t288 = -0.27, p = .79, Partial vs. No gaze t288 = -1.25, p = .21). (c) Linear mixed-effects analysis of the relationship between learning and total attention duration showed no significant relationship for all gaze conditions (p >.09 for all). (d) Total attention duration during the familiarization phase differed significantly between United Kingdom (UK) and Singaporean (SG) infants. Error bars represent the standard error of the mean (SEM). "ns" indicates not significant; "****" indicates p < .0001.

Fig. 3. Quantification of dyadic neural connectivity using generalised partial directed coherence (GPDC). (a) Illustration of concurrent estimation of directed connectivity within the adult-infant network: adult-to-adult (AA, red), infant-to-infant (II, dark blue), adult-to-infant (AI, orange), and infant-to-adult (IA, light blue). #: Since infants watched pre-recorded videos of the adult speaker, any detected infant-to-adult (IA) connections should be spurious and not significantly exceed the surrogate IA GPDC distribution. (b) Ranked GPDC strength for individual real connections (coloured lines) as compared to their surrogate data (black lines: mean; grey areas: 95% CI). Connections were deemed significant if the real data exceeded the 95th percentile of the surrogate distribution, with Benjamini-Hochberg False Discovery Rate (BHFDR) correction applied. Across all gaze conditions, significant connections were detected in the AA, II and AI directions, but not in the IA direction. 

Fig. 4. Identifying neural predictors of infant learning and language development. (a,b) Results of partial least square (PLS) regression conducted for (a) learning and (b) language development (CDI gesture scores, CDI-G) using within-infant connectivity (II GPDC, orange line) or adult-infant connectivity (AI GPDC, blue line) respectively. Significance is determined by comparison with a surrogate distribution (grey area: 95% CI, black line: mean). Only AI GPDC significantly explained infants’ learning, whereas II GPDC predicted language development scores but not learning ("*" indicates p < .05). (c,d) Absolute PLS loadings for the first component of the (c) AI GPDC prediction model for learning and (d) II GPDC prediction model for CDI gesture scores, highlighting key connections that load on each component, as estimated by bootstrapping. Respective topographical scalp plots are shown in the right panel, separated by sender and receiver maps. (e,f) Cross-validation performance (R2) of II and AI GPDC features for (e) learning and (f) language development respectively, using 10-fold cross-validation ("****" indicates p < .0001). 

Fig. 5 | Infant neural-speech entrainment (NSE). (a) Schematic illustrating the measurement of infant neural entrainment to adult speech. Entrainment strength was quantified as the cross-correlation between the Hilbert envelope of adult speech audio waveform and the power of the infant EEG signal in delta, theta and alpha bands during the first six syllables of the familiarization phase. (b) Standardized mean difference plots comparing real entrainment strength with surrogate values. Surrogate distributions were derived by randomly shuffling the temporal alignment between infant EEG and the corresponding speech envelope. Significant entrainment was only observed in the Full gaze condition, at C3 in the delta band, at F4 and Pz in the theta band, and at C3 and Cz in the alpha band. "*" indicates p < .05. P-values were corrected by BHFDR for multiple comparisons. (c) Example of surrogate tests for significant entrainment, shown here for the C3 channel in the delta EEG band, for each gaze condition. Only in the Full gaze condition did the real data exceed the 95% CI upper bound of the surrogate data distribution. "ns" indicates not significant.

Fig. 6. Mediation analysis assessing pathways linking ostensive gaze to learning. The main mediation model (middle panel) illustrating direct and indirect pathways by which gaze status might influence learning, including neural-speech entrainment (NSE, represented by delta C3) and adult-infant neural connectivity (AI GPDC, first PLS component) as potential mediators. Coloured lines represent effects that are significant in one specific gaze condition (yellow for Full gaze, red for No gaze), while black lines indicate effects that are significant across all gaze conditions. Solid arrows represent significant pathways, while dashed arrows indicate non-significant ones, annotated with standardized coefficients and p-values. The following subplots illustrate individual pathways revealed in the mediation model. "ns" indicates not significant, "*" indicates p < .05 and "****" indicates p < .0001. (a) Effect of Full gaze on AI GPDC. Full gaze is associated with significantly higher values of AI GPDC Component 1 scores compared to No gaze. (b) Correlation between AI GPDC and infant learning. (c) Effect of speaker gaze on NSE. Only Full gaze is associated with significantly higher NSE strength (delta C3 entrainment identified in Fig. 5b) compared to Partial and No gaze conditions. Error bars indicate the standard error of the mean (SEM). Similar analyses of other NSE features did not yield significant results, as detailed in Supplementary Materials Section 5. (d) Assessing the direct relationship between NSE (Delta C3) and learning. No significant correlation was observed. (e) Moderating effect of gaze on the relationship between NSE (delta C3) and AI GPDC. Gaze changes the relationship between entrainment and interpersonal connectivity, with a significant positive relationship detected only in the No gaze condition.

References
1. 	G. Csibra, G. Gergely, Natural pedagogy. Trends in cognitive sciences 13, 148–153 (2009).
2. 	Á. M. Kovács, E. Téglás, A. D. Endress, The Social Sense: Susceptibility to Others’ Beliefs in Human Infants and Adults. Science 330, 1830–1834 (2010).
3. 	A. Senju, G. Csibra, Gaze following in human infants depends on communicative signals. Current biology 18, 668–671 (2008).
4. 	E. Parise, G. Csibra, Neural responses to multimodal ostensive signals in 5-month-old infants. PloS one 8, e72360 (2013).
5. 	P. Gangopadhyay, M. Chawla, O. Dal Monte, S. W. Chang, Prefrontal–amygdala circuits in social decision-making. Nature neuroscience 24, 5–18 (2021).
6. 	S. Tremblay, K. M. Sharika, M. L. Platt, Social decision-making and the brain: A comparative perspective. Trends in cognitive sciences 21, 265–276 (2017).
7. 	S. Suzuki, J. P. O’Doherty, Breaking human social decision making into multiple components and then putting them together again. Cortex 127, 221–230 (2020).
8. 	E. A. Amadei, Z. V. Johnson, Y. Jun Kwon, A. C. Shpiner, V. Saravanan, W. D. Mays, S. J. Ryan, H. Walum, D. G. Rainnie, L. J. Young, Dynamic corticostriatal activity biases social bonding in monogamous female prairie voles. Nature 546, 297–301 (2017).
9. 	H. Walum, L. J. Young, The neural mechanisms and circuitry of the pair bond. Nature Reviews Neuroscience 19, 643–654 (2018).
10. 	M. Çetinçelik, C. F. Rowland, T. M. Snijders, Do the eyes have it? A systematic review on the role of eye gaze in infant language development. Frontiers in psychology 11, 589096 (2021).
11. 	K. Bloom, Social elicitation of infant vocal behavior. Journal of Experimental Child Psychology 20, 51–58 (1975).
12. 	V. Leong, E. Byrne, K. Clackson, S. Georgieva, S. Lam, S. Wass, Speaker gaze increases information coupling between infant and adult brains. Proceedings of the National Academy of Sciences 114, 13290–13295 (2017).
13. 	T. Farroni, G. Csibra, F. Simion, M. H. Johnson, Eye contact detection in humans from birth. Proceedings of the National Academy of Sciences 99, 9602–9605 (2002).
14. 	T. Farroni, S. Massaccesi, E. Menon, M. H. Johnson, Direct gaze modulates face recognition in young infants. Cognition 102, 396–404 (2007).
15. 	S. Hoehl, V. M. Reid, E. Parise, A. Handl, L. Palumbo, T. Striano, Looking at Eye Gaze Processing and Its Neural Correlates in Infancy—Implications for Social Development and Autism Spectrum Disorder. Child Development 80, 968–985 (2009).
16. 	J. Szufnarowska, K. J. Rohlfing, C. Fawcett, G. Gredebäck, Is ostension any more than attention? Scientific Reports 4, 5304 (2014).
17. 	Y. Okumura, Y. Kanakogi, T. Kobayashi, S. Itakura, Ostension affects infant learning more than attention. Cognition 195, 104082 (2020).
18. 	P. K. Kuhl, F.-M. Tsao, H.-M. Liu, Foreign-language experience in infancy: Effects of short-term exposure and social interaction on phonetic learning. Proc. Natl. Acad. Sci. U.S.A. 100, 9096–9101 (2003).
19. 	P. K. Kuhl, Is speech learning ‘gated’ by the social brain? Developmental Science 10, 110–120 (2007).
20. 	S. V. Wass, M. Whitehorn, I. M. Haresign, E. Phillips, V. Leong, Interpersonal neural entrainment during early social interaction. Trends in cognitive sciences 24, 329–342 (2020).
21. 	V. Reindl, K. Konrad, K. K. Poon, V. Leong, Classroom-based learning dynamics: the role of interbrain synchrony. Trends in Cognitive Sciences (2024).
22. 	L. Schwartz, J. Levy, Y. Endevelt-Shapira, A. Djalovski, O. Hayut, G. Dumas, R. Feldman, Technologically-assisted communication attenuates inter-brain synchrony. Neuroimage 264, 119677 (2022).
23. 	E. A. Piazza, L. Hasenfratz, U. Hasson, C. Lew-Williams, Infant and Adult Brains Are Coupled to the Dynamics of Natural Communication. Psychol Sci 31, 6–17 (2020).
24. 	T. Grossmann, M. H. Johnson, S. Lloyd-Fox, A. Blasi, F. Deligianni, C. Elwell, G. Csibra, Early cortical specialization for face-to-face communication in human infants. Proc. R. Soc. B. 275, 2803–2811 (2008).
25. 	S. Urakawa, K. Takamoto, A. Ishikawa, T. Ono, H. Nishijo, Selective Medial Prefrontal Cortex Responses During Live Mutual Gaze Interactions in Human Infants: An fNIRS Study. Brain Topogr 28, 691–701 (2015).
26. 	T. Nguyen, H. Schleihauf, E. Kayhan, D. Matthes, P. Vrti?ka, S. Hoehl, The effects of interaction quality on neural synchrony during mother-child problem solving. cortex 124, 235–249 (2020).
27. 	S. Hoehl, M. Fairhurst, A. Schirmer, Interactional synchrony: signals, mechanisms and benefits. Social cognitive and affective neuroscience 16, 5–18 (2021).
28. 	A. Pérez, M. Carreiras, J. A. Duñabeitia, Brain-to-brain entrainment: EEG interbrain synchronization while speaking and listening. Scientific reports 7, 4190 (2017).
29. 	S. Nozaradan, I. Peretz, A. Mouraux, Steady-state evoked potentials as an index of multisensory temporal binding. NeuroImage 60, 21–28 (2012).
30. 	G. Novembre, G. D. Iannetti, Hyperscanning alone cannot prove causality. Multibrain stimulation can. Trends in Cognitive Sciences 25, 96–99 (2021).
31. 	J. R. Saffran, R. N. Aslin, E. L. Newport, Statistical Learning by 8-Month-Old Infants. Science 274, 1926–1928 (1996).
32. 	T. Teinonen, V. Fellman, R. Näätänen, P. Alku, M. Huotilainen, Statistical language learning in neonates revealed by event-related brain potentials. BMC Neurosci 10, 21 (2009).
33. 	H. Akechi, A. Senju, H. Uibo, Y. Kikuchi, T. Hasegawa, J. K. Hietanen, Attention to eye contact in the West and East: Autonomic responses and evaluative ratings. PloS one 8, e59312 (2013).
34. 	R. E. Jack, C. Blais, C. Scheepers, P. G. Schyns, R. Caldara, Cultural confusions show that facial expressions are not universal. Current biology 19, 1543–1548 (2009).
35. 	M. S. Gobel, A. Chen, D. C. Richardson, How different cultures look at faces depends on the interpersonal context. Canadian Journal of Experimental Psychology/Revue canadienne de psychologie expérimentale 71, 258 (2017).
36. 	J. X. Haensel, T. J. Smith, A. Senju, Cultural differences in mutual gaze during face-to-face interactions: A dual head-mounted eye-tracking study. Visual Cognition 30, 100–115 (2022).
37. 	R. L. Fantz, Visual Experience in Infants: Decreased Attention to Familiar Patterns Relative to Novel Ones. Science 146, 668–670 (1964).
38. 	J. Obleser, C. Kayser, Neural Entrainment and Attentional Selection in the Listening Brain. Trends in Cognitive Sciences 23, 913–926 (2019).
39. 	A. Kösem, H. R. Bosker, A. Takashima, A. Meyer, O. Jensen, P. Hagoort, Neural entrainment determines the words we hear. Current Biology 28, 2867–2875 (2018).
40. 	U. Hasson, A. A. Ghazanfar, B. Galantucci, S. Garrod, C. Keysers, Brain-to-brain coupling: a mechanism for creating and sharing a social world. Trends in cognitive sciences 16, 114–121 (2012).
41. 	M. Wilson, T. P. Wilson, An oscillator model of the timing of turn-taking. Psychonomic Bulletin & Review 12, 957–968 (2005).
42. 	N. Cason, D. Schön, Rhythmic priming enhances the phonological processing of speech. Neuropsychologia 50, 2652–2658 (2012).
43. 	M. J. Van Ackeren, F. M. Barbero, S. Mattioni, R. Bottini, O. Collignon, Neuronal populations in the occipital cortex of the blind synchronize to the temporal dynamics of speech. elife 7, e31640 (2018).
44. 	X. Yu, S. L. Ferradal, D. D. Sliva, J. Dunstan, C. Carruthers, J. Sanfilippo, J. Zuk, L. Zöllei, E. Boyd, B. Gagoski, Functional connectivity in infancy and toddlerhood predicts long-term language and preliteracy outcomes. Cerebral Cortex 32, 725–736 (2022).
45. 	R. Feldman, S. Masalha, D. Alony, Microregulatory patterns of family interactions: cultural pathways to toddlers’ self-regulation. Journal of Family Psychology 20, 614 (2006).
46. 	A. Pérez, M. Carreiras, M. G. Dowens, J. A. Duñabeitia, Differential oscillatory encoding of foreign speech. Brain and language 147, 51–57 (2015).
47. 	D. Choi, L. J. Batterink, A. K. Black, K. A. Paller, J. F. Werker, Preverbal Infants Discover Statistical Word Patterns at Similar Rates as Adults: Evidence From Neural Entrainment. Psychol Sci 31, 1161–1173 (2020).
48. 	L. Fenson, MacArthur-Bates communicative development inventories. (2007).
49. 	A. Delorme, S. Makeig, EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis. Journal of Neuroscience Methods 134, 9–21 (2004).
50. 	L. A. Baccalá, K. Sameshima, Partial directed coherence: a new concept in neural structure determination. Biol Cybern 84, 463–474 (2001).
51. 	C. W. Granger, Investigating causal relations by econometric models and cross-spectral methods. Econometrica: journal of the Econometric Society, 424–438 (1969).
52. 	L. A. Baccala, K. Sameshima, D. Y. Takahashi, “Generalized Partial Directed Coherence” in 2007 15th International Conference on Digital Signal Processing (IEEE, Cardiff, 2007), pp. 163–166.
53. 	L. Faes, S. Erla, A. Porta, G. Nollo, A framework for assessing frequency domain causality in physiological time series with instantaneous effects. Phil. Trans. R. Soc. A. 371, 20110618 (2013).
54. 	G. M. Hoerzer, S. Liebe, A. Schloegl, N. K. Logothetis, G. Rainer, Directed coupling in local field potentials of macaque v4 during visual short-term memory revealed by multivariate autoregressive models. Frontiers in computational neuroscience, 14 (2010).
55. 	B. H. Brooker, M. W. Donald, Contribution of the speech musculature to apparent human EEG asymmetries prior to vocalization. Brain and Language 9, 226–245 (1980).
56. 	T. A. Stroganova, E. V. Orekhova, I. N. Posikera, EEG alpha rhythm in infants. Clinical neurophysiology 110, 997–1012 (1999).
57. 	E. Turk, J. Vroomen, Y. Fonken, J. Levy, M. I. Van Den Heuvel, In sync with your child: The potential of parent–child electroencephalography in developmental research. Developmental Psychobiology 64, e22221 (2022).
58. 	G. Markova, T. Nguyen, S. Hoehl, Neurobehavioral interpersonal synchrony in early development: The role of interactional rhythms. Frontiers in Psychology 10, 2078 (2019).
59. 	L. Santamaria, V. Noreika, S. Georgieva, K. Clackson, S. Wass, V. Leong, Emotional valence modulates the topology of the parent-infant inter-brain network. NeuroImage 207, 116341 (2020).
60. 	S. Georgieva, S. Lester, V. Noreika, M. N. Yilmaz, S. Wass, V. Leong, Toward the understanding of topographical and spectral signatures of infant movement artifacts in naturalistic EEG. Frontiers in neuroscience 14, 352 (2020).
61. 	B. Zoefel, R. VanRullen, EEG oscillations entrain their phase to high-level features of speech sound. Neuroimage 124, 16–23 (2016).
62. 	E. C. Lalor, A. J. Power, R. B. Reilly, J. J. Foxe, Resolving Precise Temporal Processing Properties of the Auditory System Using Continuous Stimuli. Journal of Neurophysiology 102, 349–359 (2009).
63. 	H. Luo, D. Poeppel, Phase patterns of neuronal responses reliably discriminate speech in human auditory cortex. Neuron 54, 1001–1010 (2007).
64. 	J. E. Peelle, J. Gross, M. H. Davis, Phase-locked responses to speech in human auditory cortex are enhanced during comprehension. Cerebral cortex 23, 1378–1387 (2013).
65. 	G. Chiarion, L. Sparacino, Y. Antonacci, L. Faes, L. Mesin, Connectivity analysis in EEG data: a tutorial review of the state of the art and emerging trends. Bioengineering 10, 372 (2023).
66. 	M. Çetinçelik, C. F. Rowland, T. M. Snijders, Ten-month-old infants’ neural tracking of naturalistic speech is not facilitated by the speaker’s eye gaze. Developmental Cognitive Neuroscience 64, 101297 (2023).
67. 	Y. Benjamini, Y. Hochberg, Controlling the false discovery rate: a practical and powerful approach to multiple testing. Journal of the Royal statistical society: series B (Methodological) 57, 289–300 (1995).
68. 	A. Krishnan, L. J. Williams, A. R. McIntosh, H. Abdi, Partial Least Squares (PLS) methods for neuroimaging: a tutorial and review. Neuroimage 56, 455–475 (2011).
69. 	J. Seidlitz, F. Váša, M. Shinn, R. Romero-Garcia, K. J. Whitaker, P. E. Vértes, K. Wagstyl, P. K. Reardon, L. Clasen, S. Liu, Morphometric similarity networks detect microscale cortical organization and predict inter-individual cognitive variation. Neuron 97, 231–247 (2018).
70. 	P. E. Vértes, T. Rittman, K. J. Whitaker, R. Romero-Garcia, F. Váša, M. G. Kitzbichler, K. Wagstyl, P. Fonagy, R. J. Dolan, P. B. Jones, Gene transcription profiles associated with inter-modular hubs and connection distance in human functional magnetic resonance imaging networks. Philosophical Transactions of the Royal Society B: Biological Sciences 371, 20150362 (2016).
71. 	W. J. Fu, R. J. Carroll, S. Wang, Estimating misclassification error with small samples via bootstrap cross-validation. Bioinformatics 21, 1979–1986 (2005).
72. 	W. W. Chin, “Bootstrap Cross-Validation Indices for PLS Path Model Assessment” in Handbook of Partial Least Squares, V. Esposito Vinzi, W. W. Chin, J. Henseler, H. Wang, Eds. (Springer Berlin Heidelberg, Berlin, Heidelberg, 2010; https://link.springer.com/10.1007/978-3-540-32827-8_4), pp. 83–97.
73. 	A. F. Hayes, Beyond Baron and Kenny: Statistical Mediation Analysis in the New Millennium. Communication Monographs 76, 408–420 (2009).
74. 	E. A. Blood, H. Cabral, T. Heeren, D. M. Cheng, Performance of mixed effects models in the analysis of mediated longitudinal data. BMC Med Res Methodol 10, 16 (2010).
75. 	K. J. Preacher, A. F. Hayes, Asymptotic and resampling strategies for assessing and comparing indirect effects in multiple mediator models. Behavior Research Methods 40, 879–891 (2008).


2


